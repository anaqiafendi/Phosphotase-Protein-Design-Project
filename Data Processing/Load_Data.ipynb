{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and add-ons\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "# Importing pathlib package to allow parsing of csv files\n",
    "from pathlib import Path\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nIs all the data claimed to be recorded present: True\n\nLength of Screen List Vector: 218\n\nLength of EFI ID List Vector: 218\n"
    }
   ],
   "source": [
    "# Opening the raw data file as a PATH object\n",
    "raw_data_path = Path(r\"farelli_phosphatases_raw_data.xlsx\").parent.absolute() / Path(\"farelli_phosphatases_raw_data.xlsx\")\n",
    "\n",
    "# Reading excel file from PATH object\n",
    "raw_data_file = pd.read_excel(raw_data_path)\n",
    "\n",
    "# Making variable which contains list of sheets available\n",
    "xl = pd.ExcelFile(raw_data_path)\n",
    "Sheet_Names = xl.sheet_names\n",
    "# print(Sheet_Names)\n",
    "\n",
    "# Make list of EFI IDs based on what is in excel file sheets\n",
    "EFI_ID_List = [int(x) for x in Sheet_Names if x.isdigit()]\n",
    "# print(EFI_ID_List)\n",
    "\n",
    "# Make list of EFI IDs based on sheet named Screen List for comparison\n",
    "Screen_List = pd.read_excel(raw_data_path, sheet_name='Screen List', header=None)\n",
    "Screen_List = Screen_List.to_numpy()\n",
    "Screen_List = Screen_List.transpose()\n",
    "Screen_List = Screen_List.tolist()\n",
    "Screen_List = Screen_List[0]\n",
    "# print(Screen_List)\n",
    "\n",
    "# Compares to ensure that all sheets in excel file matches what is in Screen List\n",
    "print('\\n' + 'Is all the data claimed to be recorded present: ' + str(Screen_List == EFI_ID_List))\n",
    "\n",
    "# prints length of both vectors\n",
    "print('\\n' + 'Length of Screen List Vector: ' + str(len(Screen_List)))\n",
    "print('\\n' + 'Length of EFI ID List Vector: ' + str(len(EFI_ID_List)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_protein_sequence(GI_Num):\n",
    "    '''\n",
    "    This function obtains the protein sequence using a given GI # or GI ID\n",
    "    and returns the protein sequence as a string\n",
    "    '''\n",
    "\n",
    "    # First Must Construct a URL\n",
    "    '''\n",
    "    3 Main parts of a URL required to use E-utilities and access NCBI database\n",
    "        1. Base URL: https://eutils.ncbi.nlm.nih.gov/entrez/eutils/\n",
    "        2. Utility Name: (eg: ESearch) More Here-> https://dataguide.nlm.nih.gov/eutilities/utilities.html\n",
    "        3. Parameters: Details of query such as name of database,l search terms, format of results, etc\n",
    "\n",
    "    Combining the 3 parts (example) gives us:\n",
    "        1. Base URL: https://eutils.ncbi.nlm.nih.gov/entrez/eutils/\n",
    "        2. Utility Name: ESearch = esearch.fcgi?\n",
    "        3. Parameters: db=pubmed&term=nature[journal]+AND+3D+printing\n",
    "\n",
    "    list of db allowed = https://www.ncbi.nlm.nih.gov/books/NBK25497/table/chapter2.T._entrez_unique_identifiers_ui/?report=objectonly\n",
    "\n",
    "    Result: https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=pubmed&term=nature[journal]+AND+3D+printing\n",
    "    '''\n",
    "\n",
    "    # We can use GI # as the UID so lets fetch the data from it\n",
    "    Base_URL = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/'\n",
    "    Utility_Name = 'efetch.fcgi?'\n",
    "    Parameters = 'db=protein&id=' + str(GI_Num) + '&retmode=xml'\n",
    "    URL_request = Base_URL + Utility_Name + Parameters\n",
    "    URL_request = URL_request.replace(' ','+') # Need to replace all spaces within URL for query\n",
    "    \n",
    "    response = requests.get(URL_request, auth=('anaqi.afendi@mail.utoronto.ca', '83ccb7c8bafa4df9a8120b43ecb179e92809')) # Stores response of URL request\n",
    "\n",
    "    '''\n",
    "    # Convert bytes of response.content ot string to import to xml\n",
    "    parser = ET.XMLParser(encoding='utf-8')\n",
    "    root = ET.fromstring(response.content, parser=parser)\n",
    "    protein_sequence = root.find('GBSeq').find('GBSeq_sequence').text\n",
    "    return(protein_sequence)\n",
    "    '''\n",
    "\n",
    "    # Convert bytes of response.content to string to import to xml\n",
    "    bytes_string = str(response.content, 'utf-8')\n",
    "    root = ET.fromstring(bytes_string)\n",
    "    protein_sequence = root.find('GBSeq').find('GBSeq_sequence').text \n",
    "    return(protein_sequence)\n",
    "\n",
    "    '''\n",
    "    # Try different method\n",
    "    tree = ET.parse(response.content)\n",
    "    root = tree.getroot\n",
    "    protein_sequence = root.find('GBSeq').find('GBSeq_sequence').text\n",
    "    return(protein_sequence)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Dataframe layout: 218 columns (proteins), 168 rows (metabolites)\n",
    "This section constructs the data frame\n",
    "'''\n",
    "\n",
    "# Protein GI # = Column header, obtain Protein Sequence and map using dictionary\n",
    "\n",
    "# Metabolites stored in 14 x 12 array as comments on top of activity data\n",
    "# Need to make a vector of length 168 containing metabolite name\n",
    "\n",
    "from openpyxl import Workbook\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "wb = wb = load_workbook(raw_data_path)\n",
    "ws = wb[\"501030\"] # or whatever sheet name\n",
    "\n",
    "metabolite_list = [] # Store metabolite names\n",
    "metabolite_dict = {} # Store metabolites in dictionary to map to original excel grid layoutz\n",
    "\n",
    "for r in range(7,21):\n",
    "    for c in range(3,15):\n",
    "        whole_comment = ws.cell(row=r,column=c).comment\n",
    "        metabolite = whole_comment.text.strip(\"\\n\")\n",
    "        metabolite_list.append(metabolite)\n",
    "        \n",
    "        letter = ws.cell(row=r,column=c).column_letter\n",
    "        number = ws.cell(row=r,column=c).row\n",
    "        metabolite_dict[str(letter)+str(number)] = metabolite\n",
    "\n",
    "# Establish initial variables\n",
    "activity_df = pd.DataFrame(columns=EFI_ID_List)\n",
    "GI_dict = {} # maps GI to EFI_ID, EFI_ID is key\n",
    "Protein_name_dict = {} # maps protein name to EFI_ID, EFI_ID is key\n",
    "\n",
    "# For loop to store all activitiy data into one dataframe\n",
    "for EFI_ID in EFI_ID_List:\n",
    "    data_frame = pd.read_excel(raw_data_path, sheet_name=str(EFI_ID), header=0)\n",
    "    \n",
    "    GI_Num = data_frame['GI #'][0]\n",
    "    if type(GI_Num) != str:\n",
    "        GI_Num = str(int(GI_Num))\n",
    "    GI_dict[EFI_ID] = GI_Num # Add GI Num to dictionary\n",
    "    \n",
    "    Protein_Name = str(data_frame['Name and Species'][0])\n",
    "    Protein_name_dict[EFI_ID] = Protein_Name # Add Protein name to dictionary\n",
    "\n",
    "    activities = []\n",
    "    for r in range(5,19):\n",
    "        for c in range(2,14):\n",
    "            activity = data_frame.iloc[r,c]\n",
    "            activities.append(activity)\n",
    "    \n",
    "    activity_df[EFI_ID] = activities\n",
    "\n",
    "# Return Name_and_species for searching through NCBI Database\n",
    "# Protein_Name = str(data_frame['Name and Species'][0])\n",
    "# print(Protein_Name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EFI_ID = EFI_ID_List[0]\n",
    "data_frame = pd.read_excel(raw_data_path, sheet_name=str(EFI_ID), header=0)\n",
    "activities = []\n",
    "for r in range(5,19):\n",
    "    for c in range(2,14):\n",
    "        activity = data_frame.iloc[r,c]\n",
    "        activities.append(activity)\n",
    "        print(str(r) + \",\" + str(c))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GI_Num = GI_dict[502334]\n",
    "GI_Num = 'Q836C7'\n",
    "print(get_protein_sequence(GI_Num=GI_Num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This section adds the protein_sequences to a dictionary from NCBI, it doesn't work atm'''\n",
    "# protein_dict = { get_protein_sequence(i) for i in EFI_ID_List }\n",
    "\n",
    "Protein_seq_dict = {} # maps protein sequence to EFI_ID, EFI_ID is key\n",
    "GI_Error_dict = {} # maps EFI_ID as key to GI # which returned errors\n",
    "\n",
    "def divide_chunks(long_list, num):\n",
    "    # looping till length l \n",
    "    for i in range(0, len(long_list), num):  \n",
    "        yield long_list[i:i + num] \n",
    "\n",
    "chunk_list = list(divide_chunks(long_list=EFI_ID_List,num=30))\n",
    "\n",
    "for sub_chunk in range(0,len(chunk_list)):\n",
    "    print(\"subchunk: \" + str(sub_chunk))\n",
    "    for EFI_ID in chunk_list[sub_chunk]:\n",
    "        GI_Num = GI_dict[EFI_ID]\n",
    "        try:\n",
    "            # print(get_protein_sequence(GI_Num))\n",
    "            protein_sequence = get_protein_sequence(GI_Num)\n",
    "            Protein_seq_dict[EFI_ID] = protein_sequence\n",
    "            print(\"Success with EFI_ID: \" + str(EFI_ID) + \", GI_Num: \" + str(GI_Num))\n",
    "        except Exception:\n",
    "            GI_Error_dict[EFI_ID] = GI_Num\n",
    "            print(\"Error with EFI_ID: \" + str(EFI_ID) + \", GI_Num: \" + str(GI_Num))\n",
    "        time.sleep(2)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually add proteins\n",
    "Protein_seq_dict[508512] = \"MYQVVASDLDGTLLSPDHFLTPYAKETLKLLTARGINFVFATGRHYIDVGQIRDNLGIRSYMITSNGARVHDSDGQQIFAHNLDRDIAADLFEIVRNDPKIVTNVYREDEWYMNRHRPEEMRFFKEAVFNYKLYEPGELDPQGISKVFFTCEDHEHLLPLEQAMNARWGDRVNVSFSTLTCLEVMAGGVSKGHALEAVAKMLGYTLSDCIAFGDGMNDAEMLSMAGKGCIMANAHQRLKDLHPELEVIGSNADDAVPRYLRKLYLD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save important information into pickle files and csv under \"Processed Data\" folder\n",
    "dirName = Path(r\"farelli_phosphatases_raw_data.xlsx\").parent.absolute() / Path(\"Processed Data\")\n",
    "try:\n",
    "    os.makedirs(dirName)\n",
    "    print(\"Directory \" , dirName, \" Created \")\n",
    "except FileExistsError:\n",
    "    print(\"Directory \" , dirName, \" Already Exists \")\n",
    "\n",
    "pickle.dump(EFI_ID_List, open(dirName / Path('EFI_ID_List.p'),'wb'))\n",
    "pickle.dump(Protein_seq_dict, open(dirName / Path('Protein_seq_dict.p'),'wb'))\n",
    "pickle.dump(metabolite_dict, open(dirName / Path('metabolite_dict.p'),'wb'))\n",
    "activity_df.to_csv(dirName / Path('activations.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for EFI_ID in GI_Error_dict.keys():\n",
    "    data_frame = pd.read_excel(raw_data_path, sheet_name=str(EFI_ID), header=0)\n",
    "    Name = data_frame['Name and Species'][0]\n",
    "    print(Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirName = Path(r\"farelli_phosphatases_raw_data.xlsx\").parent.absolute() / Path(\"Processed Data\")\n",
    "pickle.dump(GI_dict, open(dirName / Path('GI_dict.p'),'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the clean data into variables\n",
    "DataPath = \"Processed Data/\"\n",
    "\n",
    "\n",
    "with open(DataPath + 'EFI_ID_List.p', 'rb') as EFI_ID:\n",
    "    EFI_ID_List = pickle.load(EFI_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a section to convert FASTA aligned sequences into dictionary\n",
    "with open('Processed Data/'+'Less Than 300.aln.txt') as f:\n",
    "    textlines = list(f)\n",
    "\n",
    "Protein_aligned_dict = {}\n",
    "for ID in EFI_ID_List:\n",
    "        \n",
    "    Aligned_Sequence = ''\n",
    "        \n",
    "    # Loop over each line in text and check if the beginning matches the EFI_ID\n",
    "    for line in textlines:\n",
    "        if line.startswith(str(ID)):\n",
    "            line = line[0:67] # Only first 67 characters contain sequence info\n",
    "            line = line.strip(str(ID))\n",
    "            line = line.strip(' ')\n",
    "\n",
    "            Aligned_Sequence = Aligned_Sequence + line\n",
    "        \n",
    "    Protein_aligned_dict[ID] = Aligned_Sequence # Update dictionary\n",
    "\n",
    "\n",
    "# Dump dictionary into this path\n",
    "dirName = Path(r\"farelli_phosphatases_raw_data.xlsx\").parent.absolute() / Path(\"Processed Data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "769"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "len(Protein_aligned_dict[EFI_ID_List[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "60"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "len('------------------------------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38064bit8524944b7830403fbe33f0efba5bc94f",
   "display_name": "Python 3.8.0 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}